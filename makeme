# Project Overview
The project aimed to develop a web scraping and automation solution using Python for job searching from popular websites such as naukri.com and indeed.com. The objective was to create a system that could filter job listings based on the user's requirements and display the results in a structured format.

# Libraries Used
The following libraries were utilized in the project:
- Beautiful Soup: A Python library for web scraping and parsing HTML.
- Selenium: A powerful tool for automating web interactions, such as clicking buttons, filling forms, and navigating between pages.
- Natural Language Processing Toolkit (NLTK): A library for processing and analyzing text data, which was used for tasks such as resume parsing and job description analysis.
- OpenAI: A library for natural language processing tasks, including text generation and sentiment analysis, which was used to enhance the job search experience.
- Streamlit: A Python framework for building interactive web applications, which was used for developing the frontend user interface.

# Features
The project included the following features:
- Web scraping of job listings from naukri.com and indeed.com.
- Filtering of job listings based on user requirements.
- Implementation of a chatbot feature using OpenAI to assist users in preparing for job interviews.
- Resume upload feature to compare user resumes with job descriptions for better job matching.
- Backend functionalities for job data extraction, processing, and filtering.
- Frontend user interface development using Streamlit for job search and interaction with features.

# How the Project Was Built
The project was implemented in several stages. Initially, the team shortlisted reliable websites for gathering job data based on user requirements. Next, automation techniques were employed using Selenium to interact with the websites, inputting data and extracting job listings through web scraping. The extracted data was then processed and filtered using Beautiful Soup and NLTK to refine the job search results. Although these features were individually completed, the integration between the frontend and backend was pending, resulting in an incomplete final product.

# Usage Instructions
Although the final product was not fully completed, the backend functionalities are fully functional. Follow the instructions below to run the project:
1. Install the required libraries (Beautiful Soup, Selenium, NLTK, OpenAI, Streamlit) using pip or any other package manager.
2. Run the backend script to perform web scraping and data processing tasks, which includes extracting job listings, filtering them, and implementing the chatbot and resume upload features.
3. Launch the frontend interface using Streamlit to interact with the job search features, including inputting user requirements, viewing job listings, and utilizing the chatbot and resume upload features.

# Team Members
The project was developed by the following team members:
- Aryaman Pathal (IMT2022513)
- Rutul Patel (IMT2022021)
